// services/langGraphAgent.js
// Advanced LangGraph agent for intelligent conversation flow
// Handles routing, context management, and sophisticated responses

import { StateGraph, END } from "@langchain/langgraph";
import { ChatGroq } from "@langchain/groq";
import { PromptTemplate } from "@langchain/core/prompts";
import { ChatHistory, UserSummary } from '../models/index.js';
// Note: getUserMemory is available but not needed in this implementation
import dotenv from 'dotenv';

dotenv.config();

// State schema for the conversation
const ConversationState = {
  messages: [],
  userId: null,
  language: "en",
  intent: null,
  context: {},
  response: "",
  needsSummary: false,
  conversationId: "default"
};

// Initialize LLM
const llm = new ChatGroq({
  model: "llama-3.1-8b-instant",
  temperature: 0.7,
  maxTokens: 1000,
  apiKey: process.env.GROQ_API_KEY
});

// Intent classification prompts
const INTENT_CLASSIFIER_PROMPTS = {
  en: `Analyze this user message and classify the intent. Return ONLY one word from these options:
- casual: General conversation, greetings, jokes, small talk
- technical: Programming, development, specific technical questions
- summary: User wants to see their conversation summary or history
- help: User needs help or assistance with the system

User message: "{message}"

Intent:`,
  ar: `Ø­Ù„Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØ§Ø³ØªÙ†Ø¨Ø· Ø§Ù„Ù‚ØµØ¯ Ù…Ù†Ù‡Ø§. Ø£Ø±Ø¬Ø¹ ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©:
- casual: Ù…Ø­Ø§Ø¯Ø«Ø© Ø¹Ø§Ù…Ø©ØŒ ØªØ­ÙŠØ§ØªØŒ Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ø­Ø§Ù„ØŒ Ø­Ø¯ÙŠØ« Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ
- technical: Ø£Ø³Ø¦Ù„Ø© Ø¨Ø±Ù…Ø¬Ø©ØŒ ØªØ·ÙˆÙŠØ±ØŒ ØªÙ‚Ù†ÙŠØ©ØŒ Ø¹Ù„ÙˆÙ… Ø­Ø§Ø³ÙˆØ¨ØŒ Ù‡Ù†Ø¯Ø³Ø©
- summary: Ø·Ù„Ø¨ Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©ØŒ Ø§Ø³ØªØ¹Ø±Ø§Ø¶ Ø§Ù„ØªØ§Ø±ÙŠØ®ØŒ ØªÙ„Ø®ÙŠØµ Ù…Ø§ Ø³Ø¨Ù‚  
- help: Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©ØŒ Ø´Ø±Ø­ Ø§Ù„Ù†Ø¸Ø§Ù…ØŒ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ØŒ Ø§Ù„Ø¥Ø±Ø´Ø§Ø¯

Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: "{message}"

ØªØµÙ†ÙŠÙ Ø§Ù„Ù‚ØµØ¯:`
};

// Response prompts for different intents
const RESPONSE_PROMPTS = {
  casual: {
    en: `You are a friendly AI assistant having a casual conversation. Be warm, engaging, and natural.
Keep responses conversational and helpful.

Previous context: {context}
User message: {message}

Response:`,
    ar: `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…Ù‡Ø°Ø¨ ØªÙ‚ÙˆÙ… Ø¨Ù…Ø­Ø§Ø¯Ø«Ø© ÙˆØ¯ÙŠØ©. Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„Ø£Ø¯Ø¨ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ø£ØµÙŠÙ„ ÙˆØ§Ù„Ø«Ù‚Ø§ÙØ© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ©.

Ø¥Ø±Ø´Ø§Ø¯Ø§Øª Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©:
- Ø§Ø¨Ø¯Ø£ Ø¨ØªØ­ÙŠØ© Ù…Ù†Ø§Ø³Ø¨Ø© (Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…ØŒ Ù…Ø±Ø­Ø¨Ø§Ù‹ØŒ Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ)
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ù…Ø¹ Ø§Ù„Ø·Ø§Ø¨Ø¹ Ø§Ù„ÙˆØ¯ÙˆØ¯
- Ø£Ø¸Ù‡Ø± Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù… Ø§Ù„ØµØ§Ø¯Ù‚ Ø¨Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
- ØªØ¬Ù†Ø¨ Ø§Ù„Ø¥ÙØ±Ø§Ø· ÙÙŠ Ø§Ù„Ø±Ø³Ù…ÙŠØ© Ù„ÙƒÙ† Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø¨
- Ø§Ø³ØªØ®Ø¯Ù… ØªØ¹Ø§Ø¨ÙŠØ± Ø§Ù„ÙˆØ¯ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Ø¨Ø§Ø±Ùƒ Ø§Ù„Ù„Ù‡ ÙÙŠÙƒØŒ ÙˆÙÙ‚Ùƒ Ø§Ù„Ù„Ù‡ØŒ Ø­ÙØ¸Ùƒ Ø§Ù„Ù„Ù‡)
- Ø§Ø®ØªØªÙ… Ø¨Ø¯Ø¹ÙˆØ© Ù…Ù‡Ø°Ø¨Ø© Ù„Ù„Ø­Ø¯ÙŠØ« Ù…Ø±Ø© Ø£Ø®Ø±Ù‰

Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø³Ø§Ø¨Ù‚: {context}
Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {message}

Ø±Ø¯ ÙˆØ¯ÙˆØ¯ ÙˆÙ…Ù‡Ø°Ø¨:`
  },
  technical: {
    en: `You are an expert technical assistant. Provide detailed, accurate technical information.
Use examples, code snippets when relevant, and be thorough in your explanations.

Previous context: {context}
User message: {message}

Technical Response:`,
    ar: `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ØªÙ‚Ù†ÙŠ Ø®Ø¨ÙŠØ± Ù…ØªØ®ØµØµ. Ù‚Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªÙ‚Ù†ÙŠØ© Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ÙØµÙ„Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰.

Ø¥Ø±Ø´Ø§Ø¯Ø§Øª Ù„Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„ØªÙ‚Ù†ÙŠØ©:
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ØµØ­ÙŠØ­Ø© (Ø­Ø§Ø³ÙˆØ¨ØŒ Ø¨Ø±Ù…Ø¬Ø©ØŒ Ø´Ø¨ÙƒØ©ØŒ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª)
- Ø§Ø´Ø±Ø­ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø¨Ø·Ø±ÙŠÙ‚Ø© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ù†Ù‡Ø¬ÙŠØ©
- Ù‚Ø¯Ù… Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ© ÙˆÙ…Ù‚Ø§Ø·Ø¹ Ø§Ù„ÙƒÙˆØ¯ Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©
- Ø§Ø±Ø¨Ø· Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¨Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¹Ø±Ø¨ÙŠ ÙˆØ§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠ Ø¹Ù†Ø¯ Ø§Ù„Ø¥Ù…ÙƒØ§Ù†
- ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ø²Ø§Ø¦Ø¯ ÙˆØ§Ø¬Ø¹Ù„ Ø§Ù„Ø´Ø±Ø­ Ù…ÙÙ‡ÙˆÙ…Ø§Ù‹
- Ø§Ø³ØªØ®Ø¯Ù… Ø£Ù„ÙØ§Ø¸ Ø§Ù„ØªÙ‚Ø¯ÙŠØ± (ØªÙØ¶Ù„ØŒ Ø¨Ø¥Ø°Ù†ÙƒØŒ ÙƒÙ…Ø§ ØªØ·Ù„Ø¨)
- Ø§Ø®ØªØªÙ… Ø¨Ø³Ø¤Ø§Ù„ Ø¹Ù† ÙˆØ¶ÙˆØ­ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© Ø£Ùˆ Ø§Ù„Ø­Ø§Ø¬Ø© Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØµÙŠÙ„

Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø³Ø§Ø¨Ù‚: {context}
Ø§Ø³ØªÙØ³Ø§Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {message}

Ø§Ù„Ø±Ø¯ Ø§Ù„ØªÙ‚Ù†ÙŠ Ø§Ù„Ù…ÙØµÙ„:`
  },
  summary: {
    en: `Create a comprehensive summary of the user's conversation history and interests.
Focus on key topics discussed, preferences shown, and patterns in their questions.

Conversation history: {history}
User message: {message}

Summary:`,
    ar: `Ø£Ù†Ø´Ø¦ Ù…Ù„Ø®ØµØ§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ ÙˆÙ…Ù‡Ø°Ø¨Ø§Ù‹ Ù„ØªØ§Ø±ÙŠØ® Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØ§Ù‡ØªÙ…Ø§Ù…Ø§ØªÙ‡ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰.

Ø¥Ø±Ø´Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ù„Ø®Øµ:
- Ø§Ø¨Ø¯Ø£ Ø¨ØªØ­ÙŠØ© Ù…Ù‡Ø°Ø¨Ø© ÙˆØ§Ø´ÙƒØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù„Ù‰ Ø«Ù‚ØªÙ‡
- Ù„Ø®Øµ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ù†Ø¸Ù…Ø© ÙˆÙ…Ø±ØªØ¨Ø©
- Ø£Ø¨Ø±Ø² Ø§Ù‡ØªÙ…Ø§Ù…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØªÙØ¶ÙŠÙ„Ø§ØªÙ‡
- Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© Ø±Ø³Ù…ÙŠØ© Ù…Ø­ØªØ±Ù…Ø© Ù…Ø¹ Ø§Ù„ÙˆØ¯ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
- Ø§Ø°ÙƒØ± Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù‡Ù…Ø© ÙˆØ§Ù„Ø¥Ù†Ø¬Ø§Ø²Ø§Øª ÙÙŠ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª
- Ù‚Ø¯Ù… Ù†ØµØ§Ø¦Ø­ Ø£Ùˆ ØªÙˆØ¬ÙŠÙ‡Ø§Øª Ù…ÙÙŠØ¯Ø© Ø¥Ø°Ø§ ÙƒØ§Ù† Ø°Ù„Ùƒ Ù…Ù†Ø§Ø³Ø¨Ø§Ù‹
- Ø§Ø®ØªØªÙ… Ø¨Ø§Ù„Ø¯Ø¹Ø§Ø¡ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØ§Ù„ØªÙ…Ù†ÙŠ Ù„Ù‡ Ø§Ù„ØªÙˆÙÙŠÙ‚

Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª: {history}
Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {message}

Ù…Ù„Ø®Øµ Ø´Ø§Ù…Ù„ ÙˆÙ…Ù‡Ø°Ø¨:`
  },
  help: {
    en: `You are a helpful system assistant. Provide clear guidance about the chatbot features and capabilities.
Be informative about available commands, features, and how to use the system effectively.

Available features:
- Multi-language support (English/Arabic)
- Multiple AI models (llama-3.1-8b, llama-3.1-70b, gpt-3.5-turbo, gpt-4)
- Conversation memory and history
- User summaries and preferences
- Technical and casual conversation modes

User message: {message}

Help Response:`,
    ar: `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù†Ø¸Ø§Ù… Ù…Ø¤Ø¯Ø¨ ÙˆÙ…ÙÙŠØ¯. Ù‚Ø¯Ù… Ø¥Ø±Ø´Ø§Ø¯Ø§Øª ÙˆØ§Ø¶Ø­Ø© Ø­ÙˆÙ„ Ø¥Ù…ÙƒØ§Ù†ÙŠØ§Øª ÙˆÙ…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰.

Ø¥Ø±Ø´Ø§Ø¯Ø§Øª ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©:
- Ø§Ø¨Ø¯Ø£ Ø¨ØªØ±Ø­ÙŠØ¨ Ø­Ø§Ø± ÙˆÙ…Ù‡Ø°Ø¨ Ø¨Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
- Ø§Ø´Ø±Ø­ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ù†Ø¸Ù…Ø© ÙˆÙˆØ§Ø¶Ø­Ø©
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ØµØ­ÙŠØ­Ø© Ù„Ù„ØªÙ‚Ù†ÙŠØ§Øª
- Ù‚Ø¯Ù… Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ© Ù„ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªÙØ§Ø¯Ø© Ù…Ù† ÙƒÙ„ Ù…ÙŠØ²Ø©
- Ø£Ø¸Ù‡Ø± Ø§Ù„Ø­Ø±Øµ Ø¹Ù„Ù‰ Ø±Ø§Ø­Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØ±Ø¶Ø§Ù‡
- Ø§Ø®ØªØªÙ… Ø¨ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø§Ø³ØªØ¹Ø¯Ø§Ø¯ Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ø£ÙŠ ÙˆÙ‚Øª

Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:
- Ø¯Ø¹Ù… Ø§Ù„Ù„ØºØªÙŠÙ† Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù…Ø¹ Ø§Ø­ØªØ±Ø§Ù… Ø§Ù„Ø«Ù‚Ø§ÙØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
- Ù†Ù…Ø§Ø°Ø¬ Ø°ÙƒÙŠØ© Ù…ØªØ·ÙˆØ±Ø© Ù…ØªØ¹Ø¯Ø¯Ø©
- Ø°Ø§ÙƒØ±Ø© Ù…Ø­Ø§Ø¯Ø«Ø© Ø°ÙƒÙŠØ© ÙˆØ³Ø¬Ù„ Ù„Ù„ØªÙØ§Ø¹Ù„Ø§Øª
- Ù…Ù„Ø®ØµØ§Øª Ø´Ø®ØµÙŠØ© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØ­ÙØ¸ Ø§Ù„ØªÙØ¶ÙŠÙ„Ø§Øª  
- Ø£Ù†Ù…Ø§Ø· Ù…ØªØ®ØµØµØ© Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (ØªÙ‚Ù†ÙŠØ©ØŒ Ø¹Ø§Ø¯ÙŠØ©ØŒ Ø¹Ù„Ù…ÙŠØ©)
- Ø§Ø­ØªØ±Ø§Ù… Ø§Ù„Ø®ØµÙˆØµÙŠØ© ÙˆØ§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø«Ù‚Ø§ÙÙŠØ©

Ø§Ø³ØªÙØ³Ø§Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {message}

Ø±Ø¯ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù…Ù‡Ø°Ø¨ ÙˆØ´Ø§Ù…Ù„:`
  }
};

/**
 * Node 1: Route Query - Determines the intent of user message
 */
async function routeQuery(state) {
  try {
    console.log(`ğŸ”€ Routing query for user ${state.userId}`);
    
    const message = state.messages[state.messages.length - 1];
    const language = state.language || 'en';
    
    const intentPrompt = PromptTemplate.fromTemplate(INTENT_CLASSIFIER_PROMPTS[language]);
    const intentChain = intentPrompt.pipe(llm);
    
    const intentResponse = await intentChain.invoke({
      message: message
    });
    
    const intent = intentResponse.content.toLowerCase().trim();
    console.log(`ğŸ“ Detected intent: ${intent}`);
    
    // Get recent conversation context
    const recentHistory = await ChatHistory.findAll({
      where: { userId: state.userId },
      order: [['createdAt', 'DESC']],
      limit: 5,
      attributes: ['message', 'response', 'createdAt']
    });
    
    const context = recentHistory.map(h => `User: ${h.message}\nAI: ${h.response}`).join('\n\n');
    
    return {
      ...state,
      intent,
      context: { recentHistory: context }
    };
    
  } catch (error) {
    console.error('âŒ Error in routeQuery:', error);
    return {
      ...state,
      intent: 'casual',
      context: {}
    };
  }
}

/**
 * Node 2: Respond Chat - Handles casual conversation
 */
async function respondChat(state) {
  try {
    console.log(`ğŸ’¬ Generating casual response for user ${state.userId}`);
    
    const message = state.messages[state.messages.length - 1];
    const language = state.language || 'en';
    const context = state.context.recentHistory || '';
    
    const chatPrompt = PromptTemplate.fromTemplate(RESPONSE_PROMPTS.casual[language]);
    const chatChain = chatPrompt.pipe(llm);
    
    const response = await chatChain.invoke({
      message,
      context: context.substring(0, 500) // Limit context size
    });
    
    return {
      ...state,
      response: response.content,
      needsSummary: false
    };
    
  } catch (error) {
    console.error('âŒ Error in respondChat:', error);
    return {
      ...state,
      response: language === 'ar' 
        ? 'Ø£Ø¹ØªØ°Ø± Ø¨ØµØ¯Ù‚ Ø¹Ù† Ù‡Ø°Ø§ Ø§Ù„Ø®Ø·Ø£ Ø§Ù„ØªÙ‚Ù†ÙŠØŒ Ø­Ø¶Ø±ØªÙƒ. Ø³Ø£Ø­Ø§ÙˆÙ„ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£Ø®Ø±Ù‰ Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡. ÙŠØ±Ø¬Ù‰ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø£Ùˆ ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ø®ØªÙ„ÙØ©.'
        : 'Sorry, I encountered an error processing your message.'
    };
  }
}

/**
 * Node 3: Respond Technical - Handles technical queries
 */
async function respondTechnical(state) {
  try {
    console.log(`ğŸ”§ Generating technical response for user ${state.userId}`);
    
    const message = state.messages[state.messages.length - 1];
    const language = state.language || 'en';
    const context = state.context.recentHistory || '';
    
    const techPrompt = PromptTemplate.fromTemplate(RESPONSE_PROMPTS.technical[language]);
    const techChain = techPrompt.pipe(llm);
    
    const response = await techChain.invoke({
      message,
      context: context.substring(0, 800) // More context for technical queries
    });
    
    return {
      ...state,
      response: response.content,
      needsSummary: false
    };
    
  } catch (error) {
    console.error('âŒ Error in respondTechnical:', error);
    return {
      ...state,
      response: language === 'ar' 
        ? 'Ø£Ø¹ØªØ°Ø± Ø­Ø¶Ø±ØªÙƒØŒ ÙˆØ§Ø¬Ù‡Øª ØµØ¹ÙˆØ¨Ø© ØªÙ‚Ù†ÙŠØ© ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ Ø§Ù„Ù…ØªØ®ØµØµ. Ø£Ø±Ø¬Ùˆ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø£Ùˆ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£Ø®Ø±Ù‰ØŒ ÙˆØ³Ø£Ø¨Ø°Ù„ Ø¬Ù‡Ø¯ÙŠ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø¨Ø¥Ø°Ù† Ø§Ù„Ù„Ù‡.'
        : 'Sorry, I cannot process your technical query at the moment.'
    };
  }
}

/**
 * Node 4: Generate Summary - Creates user summary
 */
async function generateSummary(state) {
  try {
    console.log(`ğŸ“ Generating summary for user ${state.userId}`);
    
    const language = state.language || 'en';
    
    // Get comprehensive chat history
    const fullHistory = await ChatHistory.findAll({
      where: { userId: state.userId },
      order: [['createdAt', 'DESC']],
      limit: 20,
      attributes: ['message', 'response', 'model_name', 'language', 'createdAt']
    });
    
    const historyText = fullHistory.map(h => 
      `[${h.createdAt.toISOString()}] User: ${h.message}\nAI (${h.model_name}): ${h.response}`
    ).join('\n\n');
    
    const summaryPrompt = PromptTemplate.fromTemplate(RESPONSE_PROMPTS.summary[language]);
    const summaryChain = summaryPrompt.pipe(llm);
    
    const summaryResponse = await summaryChain.invoke({
      history: historyText.substring(0, 2000), // Limit for API
      message: state.messages[state.messages.length - 1]
    });
    
    // Save summary to database
    await UserSummary.upsert({
      userId: state.userId,
      summary_text: summaryResponse.content,
      language: language
    });
    
    console.log(`âœ… Summary saved for user ${state.userId}`);
    
    return {
      ...state,
      response: summaryResponse.content,
      needsSummary: true
    };
    
  } catch (error) {
    console.error('âŒ Error in generateSummary:', error);
    return {
      ...state,
      response: language === 'ar' 
        ? 'Ø£Ø¹ØªØ°Ø± Ø­Ø¶Ø±ØªÙƒØŒ Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ù„Ø®Øµ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù„Ø­Ø¸Ø© Ù†Ø¸Ø±Ø§Ù‹ Ù„Ø¸Ø±ÙˆÙ ØªÙ‚Ù†ÙŠØ©. Ø£Ø±Ø¬Ùˆ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹ ÙˆØ³Ø£ÙƒÙˆÙ† ÙÙŠ Ø®Ø¯Ù…ØªÙƒ Ø¨Ø¥Ø°Ù† Ø§Ù„Ù„Ù‡.'
        : 'Sorry, I cannot generate a summary at the moment.'
    };
  }
}

/**
 * Node 5: Respond Help - Provides system help
 */
async function respondHelp(state) {
  try {
    console.log(`â“ Generating help response for user ${state.userId}`);
    
    const message = state.messages[state.messages.length - 1];
    const language = state.language || 'en';
    
    const helpPrompt = PromptTemplate.fromTemplate(RESPONSE_PROMPTS.help[language]);
    const helpChain = helpPrompt.pipe(llm);
    
    const response = await helpChain.invoke({
      message
    });
    
    return {
      ...state,
      response: response.content,
      needsSummary: false
    };
    
  } catch (error) {
    console.error('âŒ Error in respondHelp:', error);
    return {
      ...state,
      response: language === 'ar' 
        ? 'Ø£Ø¹ØªØ°Ø± Ø¨ØµØ¯Ù‚ Ø­Ø¶Ø±ØªÙƒØŒ Ø£ÙˆØ§Ø¬Ù‡ ØµØ¹ÙˆØ¨Ø© ØªÙ‚Ù†ÙŠØ© ÙÙŠ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¢Ù†. Ø£Ø±Ø¬Ùˆ Ù…Ù†Ùƒ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ ÙˆØ³Ø£ÙƒÙˆÙ† Ø³Ø¹ÙŠØ¯Ø§Ù‹ Ù„Ø®Ø¯Ù…ØªÙƒ Ø¨Ø£ÙØ¶Ù„ Ù…Ø§ Ø£Ø³ØªØ·ÙŠØ¹.'
        : 'Sorry, I cannot provide help at the moment.'
    };
  }
}

/**
 * Conditional edge function - Routes to appropriate response node
 */
function routeToResponse(state) {
  const intent = state.intent;
  
  switch (intent) {
    case 'technical':
      return 'respond_technical';
    case 'summary':
      return 'generate_summary';
    case 'help':
      return 'respond_help';
    case 'casual':
    default:
      return 'respond_chat';
  }
}

/**
 * Create and compile the conversation graph
 */
function createConversationGraph() {
  console.log('ğŸ—ï¸ Building conversation graph...');
  
  const workflow = new StateGraph({
    channels: ConversationState
  });

  // Add nodes
  workflow.addNode("route_query", routeQuery);
  workflow.addNode("respond_chat", respondChat);
  workflow.addNode("respond_technical", respondTechnical);
  workflow.addNode("generate_summary", generateSummary);
  workflow.addNode("respond_help", respondHelp);

  // Set entry point
  workflow.setEntryPoint("route_query");

  // Add conditional edges
  workflow.addConditionalEdges(
    "route_query",
    routeToResponse,
    {
      "respond_chat": "respond_chat",
      "respond_technical": "respond_technical", 
      "generate_summary": "generate_summary",
      "respond_help": "respond_help"
    }
  );

  // Add edges to END
  workflow.addEdge("respond_chat", END);
  workflow.addEdge("respond_technical", END);
  workflow.addEdge("generate_summary", END);
  workflow.addEdge("respond_help", END);

  // Compile the graph
  const app = workflow.compile();
  console.log('âœ… Conversation graph compiled successfully');
  
  return app;
}

/**
 * Main function to process conversation with LangGraph
 * @param {number} userId - User ID
 * @param {string} message - User message
 * @param {string} language - Language preference
 * @param {string} conversationId - Conversation ID
 * @returns {Promise<string>} AI response
 */
export async function processConversationGraph(userId, message, language = 'en', conversationId = 'default') {
  try {
    console.log(`ğŸš€ Processing conversation graph for user ${userId}`);
    
    const graph = createConversationGraph();
    
    const initialState = {
      messages: [message],
      userId,
      language,
      intent: null,
      context: {},
      response: "",
      needsSummary: false,
      conversationId
    };
    
    const result = await graph.invoke(initialState);
    
    // Save conversation to memory and database
    await ChatHistory.create({
      userId,
      conversationId,
      model_name: 'langgraph-agent',
      message: message.trim(),
      response: result.response,
      language
    });
    
    console.log(`âœ… Conversation processed successfully for user ${userId}`);
    return result.response;
    
  } catch (error) {
    console.error('âŒ Error in processConversationGraph:', error);
    throw new Error(
      language === 'ar' 
        ? 'Ø£Ø¹ØªØ°Ø± Ø¨ØµØ¯Ù‚ Ø­Ø¶Ø±ØªÙƒØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø­Ø§Ø¯Ø«ØªÙ†Ø§. Ø£Ø±Ø¬Ùˆ Ù…Ù†Ùƒ Ø§Ù„ØµØ¨Ø± ÙˆØ§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ØŒ ÙˆØ¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡ Ø³Ø£ÙƒÙˆÙ† ÙÙŠ Ø®Ø¯Ù…ØªÙƒ Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„.'
        : 'Sorry, an error occurred while processing your conversation.'
    );
  }
}

/**
 * Get conversation graph statistics
 */
export function getGraphStats() {
  return {
    availableNodes: [
      'route_query',
      'respond_chat', 
      'respond_technical',
      'generate_summary',
      'respond_help'
    ],
    supportedIntents: ['casual', 'technical', 'summary', 'help'],
    supportedLanguages: ['en', 'ar']
  };
}

// Export everything
export default {
  processConversationGraph,
  getGraphStats,
  createConversationGraph
};